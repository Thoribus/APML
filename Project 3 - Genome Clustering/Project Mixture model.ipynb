{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering of genomic sequences with Mixture Models\n",
    "\n",
    "\n",
    "The goal of the project is to implement a mixture model that be able to cluster genomic sequences. \n",
    "This jupyter notebook will serve as a guide for the different steps of the implementation. \n",
    "\n",
    "### For grading, you are just expected to fill in this notebook. However the accompanying project sheet contains complementary information and it is recommended to study it before.\n",
    "\n",
    "## Representative sequences \n",
    "\n",
    "Sequences will be encoded as vectors of integers with values between 0 (A) and 3 (T). \n",
    "\n",
    "We will first code functions to estimate a representative from a set of sequences and to compute the probability of a sequence given a representative and an error rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 1 3] [1 1 1 0 3]\n",
      "[[0 1 0 1 0]\n",
      " [0 1 3 1 3]\n",
      " [1 1 3 0 2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "##Constants\n",
    "nDNA = 4\n",
    "\n",
    "c1 = np.array([0,1,3,1,3]) #c1 is the sequence ACTAT\n",
    "c2 = np.array([1,1,1,0,3]) #c2 is the sequence CCCAG\n",
    "#(s1,s2,s3) = (ACACA, ACTAT, CCTAG)\n",
    "s = np.array([[0,1,0,1,0], [0,1,3,1,3], [1,1,3,0,2]]) \n",
    "\n",
    "print(c1,c2)\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating sequences\n",
    "\n",
    "### Write a functions to simulate a set of sequences from a cluster.\n",
    "\n",
    "This function will take as input a representative `c` the error rate `mu` and `n` the number of sequences\n",
    "to generate and return a numpy array of dimension `(n, len(c))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "def simulate_seqs(n, c, mu):\n",
    "    \"\"\"\n",
    "    int * ndarray[int] * ndarray[float] -> ndarray[int,int]\n",
    "    \"\"\"\n",
    "    seqs = np.tile(c, (n,1))\n",
    "\n",
    "    #your code here\n",
    "    for i in range(n):\n",
    "        for j,nucleotide in enumerate(seqs[i]):\n",
    "            if np.random.choice([True,False],p=[mu,1-mu]):\n",
    "                seqs[i][j] = np.random.choice(np.delete(np.arange(nDNA),nucleotide))\n",
    "    return seqs\n",
    "\n",
    "##Simulate 100 sequences with mu=0.1 and verify that the average percentage\n",
    "##of mutation is indeed 10%\n",
    "sims = simulate_seqs(100,c1,0.1)\n",
    "\n",
    "# for 100 generated sequences of length n, we have 100*n times the possibility of\n",
    "# a mutation occurrence. With our sequences of length 5 we have 500 possibilities of \n",
    "# a mutation occurrence. With 10% probability, this should be around 50 changes\n",
    "# from the initial sequence.\n",
    "\n",
    "# TODO: Hamming distance?\n",
    "\n",
    "changes = 0\n",
    "seq_change = 0\n",
    "for sim in sims:\n",
    "    if np.array_equal(c1,sim):\n",
    "        seq_change+=1\n",
    "    for i,nucleotide in enumerate(sim):\n",
    "        if nucleotide != c1[i]:\n",
    "            changes+=1\n",
    "\n",
    "print(changes)\n",
    "print(seq_change) ##50-60% of the sequences are changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing sequence probabilities\n",
    "\n",
    "### 1. Write a function that computes the log probability for a set of sequences\n",
    "\n",
    "It will take as input a matrix of sequences, the representative, and the  error rate `mu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -7.29604783  -0.4715534  -10.70829505]\n",
      "expected result: [ -7.29604783  -0.4715534  -10.70829505]\n",
      "[-14.12054227 -10.70829505  -7.29604783]\n"
     ]
    }
   ],
   "source": [
    "def LogProbabilities(s, c, mu,compute_log=True):\n",
    "    \"\"\"\n",
    "    ndarray[int,int] *ndarray[int] * float -> ndarray[float]\n",
    "    \"\"\"\n",
    "    nseqs,L = s.shape\n",
    "    logprobas = np.zeros(nseqs, dtype=float)\n",
    "    ##\n",
    "    ## Your code here\n",
    "    for i in range(nseqs):\n",
    "        hamming_d = np.count_nonzero(s[i]!=c)\n",
    "        logprobas[i] = (1-mu)**(L-hamming_d)*(mu/3)**hamming_d\n",
    "    if compute_log:\n",
    "        return np.log(logprobas)\n",
    "    return(logprobas)\n",
    "    \n",
    "\n",
    "print (LogProbabilities(s, c1, 0.09))\n",
    "print(\"expected result:\",np.log([0.91**3*0.03**2, 0.91**5, 0.91**2 * 0.03**3]))\n",
    "print (LogProbabilities(s, c2, 0.09))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute the class posteriors \n",
    "\n",
    "This function takes as argument a set of representatives, a set of error rate and the class priors and returns a \n",
    "matrix of all the class posterior. You can use the function `LogProbabilities` to simplify the computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.98914355e-01 1.08564536e-03]\n",
      " [9.99964172e-01 3.58281206e-05]\n",
      " [3.19148936e-02 9.68085106e-01]]\n"
     ]
    }
   ],
   "source": [
    "def ClassPosterior(s, list_c, list_mu, priors):\n",
    "    \"\"\"\n",
    "    ndarray[int, int] * ndarray[int] * ndarray[float] * ndarray[float] -> ndarray[float, float]\n",
    "    \n",
    "    \"\"\"\n",
    "    nseqs, L = s.shape\n",
    "    K = len(list_c)\n",
    "    ###\n",
    "    ### Your code here\n",
    "    class_posteriors = np.zeros((nseqs, K))\n",
    "\n",
    "    for k in range(K):\n",
    "        probs = LogProbabilities(s, list_c[k], list_mu[k],compute_log=False) \n",
    "        class_posteriors[:, k] = probs * priors[k]\n",
    "    # Normalize\n",
    "    class_posteriors /= np.max(class_posteriors, axis=1, keepdims=True)\n",
    "    class_posteriors /= np.sum(class_posteriors, axis=1, keepdims=True)\n",
    "\n",
    "    return class_posteriors\n",
    "\n",
    "mus = np.array([0.09,0.09])\n",
    "pi = np.array([0.5, 0.5])\n",
    "               \n",
    "print(ClassPosterior(s, [c1, c2], mus, pi))\n",
    "##Expected output\n",
    "#[[9.98914355e-01 1.08564536e-03]\n",
    "# [9.99964172e-01 3.58281206e-05]\n",
    "# [3.19148936e-02 9.68085106e-01]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute the loglikelihood of the sequences\n",
    "\n",
    "Compute the conditional loglikelihood of the sequences by integrating over all possible class membership (note that you will have to compute an exponential of the logprobabilities computed with the previous function.\n",
    "$$\n",
    "\\log P(s_1,\\ldots, s_n \\mid (c_1, \\ldots, c_K), (\\mu_1, \\ldots, \\mu_K), (\\pi_1,\\ldots, \\pi_K)) = \n",
    "\\sum_{i=1}^n \\log \\Big(\\sum_{i=1}^K \\pi_k P(s_i \\mid z_i = k)\\Big)\n",
    "$$\n",
    "(note: $z_i$ is the class of the sequence $s_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17.109533265532214\n"
     ]
    }
   ],
   "source": [
    "def conditional_loglikelihood(s, list_c, list_mu, priors):\n",
    "    \"\"\"\n",
    "    ndarray[int, int] * ndarray[int] * ndarray[float] * ndarray[float] -> float\n",
    "    \"\"\"\n",
    "    nseqs, L = s.shape\n",
    "    K = len(list_c)\n",
    "    ##Your code here\n",
    "    \n",
    "    loglikelihood = 0.0\n",
    "    for i in range(nseqs):\n",
    "        inner_sum = 0.0\n",
    "        for k in range(K):\n",
    "            inner_sum += priors[k] * np.exp(LogProbabilities(s[i:i+1], list_c[k], list_mu[k]))[0]\n",
    "        loglikelihood += np.log(inner_sum)\n",
    "    \n",
    "    return loglikelihood\n",
    "\n",
    "result = conditional_loglikelihood(s, [c1, c2], mus, pi)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating class representatives and implementing EM _light_\n",
    "\n",
    "In the following we will implement a simplified version of EM with binary class allocations (each sequence is in the class where it has the highest posterior probability).\n",
    "\n",
    "We will first write a function to update class representative and error rate from a set of sequences and then\n",
    "implement EM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write two functions, one to estimate the sequence representative and one to estimate the error rate\n",
    "\n",
    "From set of sequences, we compute first the profile of the sequences at each position and as consensus the most\n",
    "represented nucleotide. We then estimate the error rate by counting the number of differences to the consensus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 3. 1. 0.]\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def estimate_representative(s):\n",
    "    \"\"\"\n",
    "    ndarray[int, int] -> ndarray[int]\n",
    "    from a n * L matrix of sequences, returns the consensus sequence \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    nseqs,L = s.shape\n",
    "    profile = np.zeros(L)\n",
    "    for i in range(L):\n",
    "        profile[i] = np.argmax(np.bincount(s[:,i], minlength=4))\n",
    "    return profile\n",
    "    \n",
    "def estimate_error_rate(s, c):\n",
    "    \"\"\"\n",
    "    ndarray[int, int] -> float\n",
    "    \"\"\"\n",
    "    nseqs, L = s.shape\n",
    "    nerrors = np.count_nonzero(s!=c)\n",
    "    return nerrors/(L*nseqs)\n",
    "\n",
    "c = estimate_representative(s)\n",
    "mu = estimate_error_rate(s,c)\n",
    "print(c) # [0 1 3 1 0]\n",
    "print(mu) # 0.3333333333333333\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementing EM\n",
    "\n",
    "We will implement the EM algorithm with fixed class allocation:\n",
    "\n",
    "0. fix the number of clusters $K$\n",
    "1. Initialise random allocation of the representative\n",
    "2. Until convergence\n",
    "    - Compute the class posteriors for each sequence\n",
    "    - Allocate each sequence to the most probable class\n",
    "    - Update cluster representative and error rate\n",
    "\n",
    "Note that this algorithm works in the spirit of the K-means algorithm in the sense that the class allocations are fixed at each step. However, an adapation of K-means to multinoulli would only estimate class centers. Here we estimate class centers $c_k$ and the error rate $\\mu_k$ for each class.\n",
    "\n",
    "For the convergence criterion we can monitor the class representatives and stop when they do not change anymore.\n",
    "\n",
    "The function will return a matrix (K x L) of the class representatives, a vector of the class proportions and optionally a vector of the likelihoods at each iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 0, 3],\n",
       "        [0, 1, 3, 1, 3]]),\n",
       " array([0.515, 0.485]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def EM(s,K, priors=None):\n",
    "    \"\"\"\n",
    "    ndarray[int,int] * int -> (ndarray[int, int], ndarray[float], ndarray[float])\n",
    "    \"\"\"   \n",
    "    break_point=100\n",
    "    nseqs, L = s.shape\n",
    "    representative = np.random.choice(nDNA,size=(K,L)) #initilization of random representative\n",
    "    error_rate = np.full((K), 0.09) #initialize error rate\n",
    "    if priors==None:\n",
    "        priors = np.full((K), 1/K) #initialize priors\n",
    "    cnt = 0\n",
    "    \n",
    "    #do until convergence:\n",
    "    while(True):\n",
    "        prev_rep = np.copy(representative)\n",
    "        posteriors = ClassPosterior(s, representative, error_rate, priors)\n",
    "        cluster_assignment = np.argmax(posteriors, axis=1)\n",
    "        for k in range(K):\n",
    "            cur_seq = s[cluster_assignment == k]\n",
    "            new_rep = estimate_representative(cur_seq)\n",
    "            new_error_rate = estimate_error_rate(cur_seq, new_rep)\n",
    "            \n",
    "            representative[k] = new_rep\n",
    "            error_rate[k] = new_error_rate\n",
    "            priors[k] = len(cur_seq)/nseqs\n",
    "        cnt+=1\n",
    "        if cnt>=break_point:\n",
    "            break\n",
    "        if np.array_equal(prev_rep, representative):\n",
    "            break\n",
    "    print(cnt)\n",
    "    return representative, priors\n",
    "new_sims = np.concatenate((simulate_seqs(100,c1,0.1),simulate_seqs(100,c2,0.1)))\n",
    "EM(new_sims,2)\n",
    "#schaut ganz gut aus.. sind die c1,c2 reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validating on simulated data\n",
    "\n",
    "\n",
    "The file `simul_3_clusters.csv` contains a simulation of 400 sequences of length 100 sampled from 3 clusters with proportions $\\pi = (0.6, 0.3, 0.1) $. \n",
    "- Apply EM on the simulated sequences \n",
    "- Verify that the estimation of the clusters worked correctly by checking the estimated class representative and the prior (file `simul_representatives.csv`)\n",
    "- Verify the class allocations as well (file `simul_sequences_class.csv`)\n",
    "- What are the error rates $(\\mu_1, \\mu_2, \\mu_3)$ for each of the classes?\n",
    "\n",
    "### 4. Determining the number of clusters\n",
    "\n",
    "Run EM for $K$ ranging from 2 to 10 and record the loglikelihood for each adjusted model adjusted.\n",
    "Plot the value of the loglikelihood against $K$, what do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write the code here to check the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to real data: Ebola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna apply our clustering method to real sequences from the Ebola epidemics in west Africa in 2014-2016. \n",
    "We will first start with a simple \"detective work\" on a set of simple sequences to understand the questions related to outbreak analysis.  \n",
    "\n",
    "### 1. Detective training\n",
    "\n",
    "This part is condensed from an activity proposed on the excellent [HHMI biointeractive website](https://www.biointeractive.org/classroom-resources/ebola-disease-detectives). It is recommended start by reading this [short summary on the Ebola epidemics](https://www.biointeractive.org/sites/default/files/Introduction-to-Ebola.pdf). \n",
    "\n",
    "Below is a set of DNA sequences that includes the reference sample from Guinea and 15 Ebola DNA sequences from samples of patients in Sierra Leone. We will reason on those sequences to understand better how genomic information can help understanding the spread of a virus. \n",
    "\n",
    "\n",
    "- The shaded nucleotides in sequences 1–15 represent mutations that occurred in these different viruses compared to the reference sequence. (Remember that the reference sequence is from a virus that was present at the start of the outbreak.) \n",
    "- Move the Ebola sequences 1–15 around to identify patterns in the mutations.\n",
    "- Group sequences according to any patterns you see.\n",
    "- Every sequence should be in a group, even if they are not identical. Use your groupings to answer the analysis questions.\n",
    "\n",
    "<div>\n",
    "<img src=\"ebola_sequences.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "#### 1.a Write your groups below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b What was your criteria to construct this grouping? Could you have used an alternative criteria?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c If a sequence has a larger number of mutations when compared to the reference sequence, does that mean it is from earlier or later in the outbreak? Explain your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.d Create a visual that highlights the relationship between your groups. Examples of effective visuals include flowcharts and trees. Be sure that your visual includes an arrow indicating passage of time during the outbreak. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing the clustering algorithm\n",
    "\n",
    "Let's apply our clustering algorithm to a set of sequences from the 2014-2016 epidemics. We started from the genome data available on [this website](https://github.com/ebov/space-time) listing 1610 sequences during the pandemics. We selected a subset of sequences and recorded only positions that are changing. We also prepared the data as a numpy array. \n",
    "\n",
    "#### 2.a Run the mixture model for different values of $k$ \n",
    "\n",
    "#### 2.b Determine the most suited value for $k$. What about the resulting groups, are they very diverse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "sequences = pkl.load( open('ebola.pkl', 'rb'))\n",
    "\n",
    "# Running EM with different values for k\n",
    "\n",
    "\n",
    "# Determine the best value for k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.c Do you see limitations in applying the clustering algorithm to an outbreak? What are the advantages? What would be an alternative method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
